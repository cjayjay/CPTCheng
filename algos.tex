\section{Gradient-based algorithm for CPT optimization (CPT-SPSA)}
\label{sec:1spsa}

\begin{figure}[h]
\centering
\tikzstyle{block} = [draw, fill=white, rectangle,
   minimum height=3em, minimum width=6em]
\tikzstyle{sum} = [draw, fill=white, circle, node distance=1cm]
\tikzstyle{input} = [coordinate]
\tikzstyle{output} = [coordinate]
\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]
\scalebox{0.85}{\begin{tikzpicture}[auto, node distance=2cm,>=latex']
% We start by placing the blocks
\node (theta) {\large$\bm{\theta_n}$};
\node [sum, fill=blue!20,above right=0.6cm of theta, xshift=1cm] (perturb) {\large$\bm{+}$};
\node [sum,fill=red!20, below right=0.6cm of theta, xshift=1cm] (perturb1) {\large$\bm{-}$};
\node [above=0.5cm of perturb] (noise) {\large$\bm{\delta_n \Delta_n}$};
\node [below=0.5cm of perturb1] (noise1) {\large$\bm{\delta_n \Delta_n}$};    
\node [block,fill=blue!20, right=2.5cm of perturb,label=above:{\color{bleu2}\bf Prediction}, minimum height=4em,] (psim) {\makecell{\large\bf CPT-value estimate\\[1ex] \large\bf for $\bm{\theta_n+\delta_n \Delta_n}$}}; 
\node [block,fill=red!20, right=2.5cm of perturb1] (sim) {\makecell{\large\bf CPT-value estimate\\[1ex] \large\bf for $\bm{\theta_n-\delta_n \Delta_n}$}}; 
\node [block, fill=green!20,below right=2cm of psim,label=above:{\color{bleu2}\bf Control}, minimum height=8em, yshift=2.5cm,text width=3.2cm] (update) {\large\bf{Gradient descent }\\[2ex]\large\bf{~~~using SPSA}};
\node [right=0.7cm of update] (thetanext) {\large$\bm{\theta_{n+1}}$};

\draw [->] (perturb) -- node[above] {\textbf{Obtain}} node[below] {$\bm{m_n}$ \textbf{samples}}  (psim);
\draw [->] (perturb1) -- node[above] {\textbf{Obtain}} node[below] {$\bm{m_n}$ \textbf{samples}}  (sim);
\draw [->] (noise) -- (perturb);
\draw [->] (noise1) -- (perturb1);
\draw [->] (psim) -- %node {$\hat J^{\theta(t)+p_1(t)}(x_0)$}
(update.150);
\draw [->] (sim) --  %node {$\hat J^{\theta(t)+p_2(t)}(x_0)$} 
(update.205);
\draw [->] (update) -- (thetanext);
\draw [->] (theta) --   (perturb);
\draw [->] (theta) --   (perturb1);
\end{tikzpicture}}
\caption{Overall flow of CPT-SPSA-G.}
\label{fig:algorithm-flow}
\end{figure}

\subsection{Gradient estimation} 
Given that we operate in a learning setting and only have biased estimates of the CPT-value from Algorithm \ref{alg:holder-est}, we require a simulation optimization scheme that estimates $\nabla \C(X^\theta)$.  
Simultaneous perturbation methods are a general class of stochastic gradient schemes that optimize a function given only noisy sample values - see \cite{Bhatnagar13SR} for textbook introduction. SPSA is a well-known scheme that estimates the gradient using two sample values. In our context, at any iteration $n$ of CPT-SPSA-G, with parameter $\theta_n$, the gradient $\nabla \C(X^{\theta_n})$ is estimated as follows: For any  $i=1,\ldots,d$,
$$\widehat \nabla_{i} \C(X^\theta) = \dfrac{\overline \C_n^{\theta_n+\delta_n \Delta_n} - \overline \C_n^{\theta_n-\delta_n \Delta_n}}{2 \delta_n \Delta_n^{i}},$$
where $\delta_n$ is a positive scalar that satisfies (A3) below, $\Delta_n = \left( \Delta_n^{1},\ldots,\Delta_n^{\L\M}\right)\tr$, where $\{\Delta_n^{i}, i=1,\ldots,\L\M\}$, $n=1,2,\ldots$ are i.i.d. Rademacher, independent of $\theta_0,\ldots,\theta_n$ and $\overline \C_n^{\theta_n+\delta_n \Delta_n}$ (resp. $\overline \C_n^{\theta_n+\delta_n \Delta_n}$) denotes the CPT-value estimate that uses $m_n$ samples of the r.v. $X^{\theta_n+\delta_n \Delta_n}$ (resp. $\overline X^{\theta_n-\delta_n \Delta_n}$).
%From the asymptotic mean square analysis that we present later, it is optimal to set $\delta_n = \delta_0/n^{0.16}$.
The (asymptotic) unbiasedness of the gradient estimate is proven in Lemma \ref{lemma:1spsa-bias}.

This idea of using two-point feedback for estimating the gradient has been employed in various settings. Machine learning applications include bandit/stochastic convex optimization - cf. 
\cite{hazan2015online}, \cite{duchi2013optimal}. However, the idea applies to non-convex functions as well - cf. \cite{spall2005introduction}, \cite{Bhatnagar13SR}.


\subsection{Update rule} We incrementally update the parameter $\theta$ in the descent direction as follows: For every state $i=1,\ldots,\L\M$,
\begin{align}
\theta^{i}_{n+1} = \Gamma_{i}\left(\theta^{i}_n - \gamma_n  \widehat \nabla_{i} \C(X^{\theta_n})\right),
\label{eq:theta-update}
\end{align}
where  $\gamma_n$ is a step-size chosen to satisfy (A3) below and
$\Gamma=\left(\Gamma_{1},\ldots,\Gamma_{d}\right)$ is an operator that ensures that the update \eqref{eq:theta-update} stays bounded within a compact and convex set $\Theta$. 
Fig. \ref{fig:algorithm-flow} illustrates the overall flow of the gradient algorithm based on SPSA, while Algorithm \ref{alg:1spsa}  presents the pseudocode.  


%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
\algblock{PEval}{EndPEval}
\algnewcommand\algorithmicPEval{\textbf{\em CPT-value Estimation (Trajectory 1)}}
 \algnewcommand\algorithmicendPEval{}
\algrenewtext{PEval}[1]{\algorithmicPEval\ #1}
\algrenewtext{EndPEval}{\algorithmicendPEval}

\algblock{PEvalPrime}{EndPEvalPrime}
\algnewcommand\algorithmicPEvalPrime{\textbf{\em CPT-value Estimation (Trajectory 2)}}
 \algnewcommand\algorithmicendPEvalPrime{}
\algrenewtext{PEvalPrime}[1]{\algorithmicPEvalPrime\ #1}
\algrenewtext{EndPEvalPrime}{\algorithmicendPEvalPrime}

\algblock{PImp}{EndPImp}
\algnewcommand\algorithmicPImp{\textbf{\em Gradient descent}}
 \algnewcommand\algorithmicendPImp{}
\algrenewtext{PImp}[1]{\algorithmicPImp\ #1}
\algrenewtext{EndPImp}{\algorithmicendPImp}

\algtext*{EndPEval}
\algtext*{EndPEvalPrime}
\algtext*{EndPImp}
%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[t]
\begin{algorithmic}
    \State {\bf Input:}  initial parameter $\theta_0$, perturbation constants $\delta_n>0$, sample size $\{m_n\}$, step-sizes $\{\gamma_n\}$, operator $\Gamma$.
\For{$n = 0,1,2,\ldots$}	
	\State Generate $\{\Delta_n^i, i=1,\ldots,\L\M\}$ using Rademacher distribution, independent of $\{\Delta_m, m=0,1,\ldots,n-1\}$
	\PEval
	    \State Simulate $m_n$ samples using parameter $(\theta_n+\delta_n \Delta_n)$
	    \State Obtain CPT-value estimate $\overline \C_n^{\theta_n+\delta_n \Delta_n}$
	    \EndPEval
	    \PEvalPrime
  	    \State Simulate $m_n$ samples using parameter $\theta_n-\delta_n \Delta_n$
	    \State Obtain CPT-value estimate $\overline \C_n^{\theta_n-\delta_n \Delta_n}$
	    \EndPEvalPrime
	    \PImp
		\State $\theta^{i}_{n+1} = \Gamma_i\left(\theta^{i}_n - \gamma_n \widehat \nabla_{i} \C(X^{\theta_n})\right)$
		\EndPImp
\EndFor
\State {\bf Return} $\theta_n$
\end{algorithmic}
\caption{Structure of CPT-SPSA-G algorithm.}
\label{alg:1spsa}
\end{algorithm}

 \begin{figure}
    \centering
     \begin{tabular}{cc}
\begin{subfigure}[b]{0.5\textwidth}
\scalebox{0.6}{\begin{tikzpicture}[auto, node distance=2cm,>=latex']
% We start by placing the blocks
\node (theta) {$\boldsymbol{\theta}$};
\node [block, fill=blue!20,right=0.6cm of theta,align=center] (sample) {\makecell{\textbf{Measurement}\\\textbf{ Oracle}}}; 
\node [right=0.6cm of sample] (end) {$\boldsymbol{\mathbf{f(\theta) + \xi}}$};
\node [ above right= 0.6cm of end] (bias) {\textbf{Zero mean}};
\draw [->] (theta) --  (sample);
\draw [->] (sample) -- (end);
\path [darkgreen,->] (bias) edge [bend left] (end);
\end{tikzpicture}}
\caption{Simulation optimization}
\end{subfigure}
&
\begin{subfigure}[b]{0.5\textwidth}
\scalebox{0.6}{\begin{tikzpicture}[auto, node distance=2cm,>=latex']
% We start by placing the blocks
\node (theta) {$\boldsymbol{\theta, \epsilon}$};
\node [block, fill=blue!20,right=0.6cm of theta,align=center] (sample) {\makecell{\textbf{CPT}\\\textbf{ Estimator}}}; 
\node [right=0.6cm of sample] (end) {$\boldsymbol{\mathbf{\C(X^\theta) + \epsilon}}$};
\node [ above right= 0.6cm of end] (bias) {\textbf{Controlled bias}};
\draw [->] (theta) --  (sample);
\draw [->] (sample) -- (end);
\path [red,->] (bias) edge [bend left] (end);
\end{tikzpicture}}
\caption{CPT-value optimization}
\end{subfigure}
\end{tabular}
\caption{Illustration of difference between classic simulation optimization and CPT-value optimiziation settings}
\label{fig:opt-diff}
\end{figure}

\paragraph{On the number of samples $m_n$ per iteration:}
As illustrated in Figure \ref{fig:opt-diff}, the CPT-value estimation scheme is biased, i.e., providing samples with parameter $\theta_n$ at instant $n$, we obtain its CPT-value estimate as $\C(X^{\theta_n}) + \epsilon_n^\theta$ with $\epsilon_n^\theta$ denoting the bias. The bias can be controlled by increasing the number of samples $m_n$ in each iteration of CPT-SPSA (see Algorithm \ref{alg:1spsa}). This is unlike classic simulation optimization settings where one only sees function evaluations with zero mean noise and there is no question of deciding on $m_n$ to control the bias as we have in our setting.

To motivate the choice for $m_n$, we first rewrite the update rule \eqref{eq:theta-update} as follows:
\begin{align*}
\theta^{i}_{n+1}  = & \Gamma_{i}\bigg( \theta^{i}_n -  \gamma_n \bigg( \frac{\C(X^{\theta_n +\delta_n\Delta_n}) - \C(X^{\theta_n-\delta_n\Delta_n})}{2\delta_n\Delta_n^{i}}\bigg) + \underbrace{\frac{(\epsilon_n^{\theta_n +\delta_n\Delta_n} - \epsilon_n^{\theta_n-\delta_n\Delta_n})}{2\delta_n\Delta_n^{i}}}_{\kappa_n}\bigg).
\end{align*}
Let $\zeta_n = \sum_{l = 0}^{n} \gamma_l \kappa_{l}$. Then, a critical requirement that allows us to ignore the bias term $\zeta_n$ is the following condition (see Lemma 1 in Chapter 2 of \cite{borkar2008stochastic}): 
$$\sup_{l\ge0} \left (\zeta_{n+l} - \zeta_n \right) \rightarrow 0 \text{ as } n\rightarrow\infty.$$ 
While Theorems \ref{prop:holder-asymptotic}--\ref{prop:holder-dkw} show that the bias $\epsilon^\theta$ is bounded above, to establish convergence of the policy gradient recursion \eqref{eq:theta-update}, we increase the number of samples $m_n$ so that the bias vanishes asymptotically.  Assumption (A3) provides a condition on the rate at which $m_n$ has to increase.

\noindent\textbf{Assumption (A3).}  The step-sizes $\gamma_n$ and the perturbation constants 
$\delta_n$ are positive $\forall n$ and satisfy
\begin{align*}
\gamma_n, \delta_n \rightarrow 0, \frac{1}{m_n^{\alpha/2}\delta_n}\rightarrow 0,  \sum_n \gamma_n=\infty \text{ and } \sum_n \frac{\gamma_n^2}{\delta_n^2}<\infty. 
\end{align*}
While the conditions on $\gamma_n$ and $\delta_n$ are standard for SPSA-based algorithms, the condition on $m_n$ is motivated by the earlier discussion. 
A simple choice that satisfies the above conditions is $\gamma_n = a_0/n$, $m_n = m_0 n^\nu$ and $\delta_n = \delta_0/{n^\gamma}$, for some $\nu, \gamma >0$ with $\gamma > \nu\alpha/2$.

\subsection{Convergence result}
\begin{theorem}
\label{thm:1spsa-conv}
Assume (A1)-(A3).
Consider the  ordinary differential equation (ODE): 
$$\dot\theta^{i}_t = \check\Gamma_{i}\left(- \nabla \C(X^{\theta^{i}_t})\right), \text{ for }i=1,\dots,d,$$ 
where 
$$\check\Gamma_{i}(f(\theta)) := \lim\limits_{\alpha \downarrow 0} \frac{\Gamma_{i}(\theta + \alpha f(\theta)) - \theta}{\alpha}, \textrm{ for any continuous }f(\cdot).$$
 Let $\K = \{\theta \mid \check\Gamma_{i} \left(\nabla_i V^{\theta}(x^0)\right)=0, \forall i=1,\ldots,d\}$. Then,
$$\theta_n \rightarrow \K \text{ a.s. as } n\rightarrow \infty.$$
\end{theorem}
\begin{proof}
 See Section \ref{appendix:1spsa}.
\end{proof}

%See Theorem \ref{thm:1spsa-asymp-normal} in Appendix \ref{appendix:1spsa} for a central limit theorem result, which shows that $n^{\beta/2}(\theta_n - \theta^*)$ is asymptotically normal.  


%%%%%%%%%%
\section{Newton algorithm for CPT-value optimization (CPT-SPSA-N)}
\label{sec:2spsa}
\subsection{Need for second-order methods}
While stochastic gradient descent methods are useful in minimizing the CPT-value given biased estimates, they are sensitive to the choice of the step-size sequence $\{\gamma_n\}$.  In particular, for a step-size choice $\gamma_n = \gamma_0/n$, if $a_0$ is not chosen to be greater than $1/3 \lambda_{min}(\nabla^2 \C(X^{\theta^*}))$, then the optimum rate of convergence is not achieved. Here $\lambda_{\min}$ denotes the minimum eigenvalue, while $\theta^*\in \K$ (see Theorem \ref{thm:1spsa-conv}). A standard approach to overcome this step-size dependency is to use iterate averaging, suggested independently by Polyak \cite{polyak1992acceleration} and Ruppert \cite{ruppert1991stochastic}. The idea is to use larger step-sizes $\gamma_n = 1/n^\varsigma$, where $\varsigma \in (1/2,1)$, and then combine it with averaging of the iterates. However, it is well known  that iterate averaging is optimal only in an asymptotic sense, while finite-time bounds show that the initial condition is not forgotten sub-exponentially fast (see 
Theorem 2.2 in \cite{fathi2013transport}). Thus, it is optimal to average iterates only 
after a sufficient number of iterations have passed and all the iterates are very close to the optimum. However, the latter situation serves as a stopping condition in practice.

An alternative approach is to employ step-sizes of the form $\gamma_n = (a_0/n) M_n$, where $M_n$ converges to $\left(\nabla^2 \C(X^{\theta^*})\right)^{-1}$, i.e., the inverse of the Hessian of the CPT-value at the optimum $\theta^*$. Such a scheme gets rid of the step-size dependency (one can set $a_0=1$) and still obtains optimal convergence rates. This is the motivation behind having a second-order optimization scheme.

\subsection{Gradient and Hessian estimation}
We estimate the Hessian of the CPT-value function using the scheme suggested by \cite{bhatnagar2015simultaneous}. As in the case of the first-order method, we use Rademacher random variables to simultaneously perturb all the coordinates. However, in this case, we require three system trajectories with corresponding  parameters $\theta_n+\delta_n(\Delta_n+\widehat\Delta_n)$, $\theta_n-\delta_n(\Delta_n+\widehat\Delta_n)$ and $\theta_n$, where $\{\Delta_n^i, \widehat\Delta_n^i, i=1,\ldots,d\}$ are i.i.d. Rademacher and independent of $\theta_0,\ldots,\theta_n$. Using the CPT-value estimates for the aforementioned  parameters, we estimate the Hessian and the gradient of the CPT-value function as follows: For $i,j=1,\ldots,d$, set
\begin{align*}
&\widehat \nabla_{i} \C(X_n^{\theta_n})=\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} - \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n}}{2\delta_n \Delta_n^{i}},\\ 
&\widehat H_n^{i,j}=\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} + \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n} - 2\widehat V_n^{\theta_n}(x^0)}{\delta_n^2 \Delta_n^{i}\widehat\Delta_n^{j}}.
\end{align*}
Further, set  $\widehat H_n^{i,j} = \widehat H_n^{j, i}$, for $i,j=1,\ldots,d$.
Notice that the above estimates require three samples, while the second-order SPSA algorithm proposed first in \cite{spall2000adaptive} required four.
%
Both the gradient estimate $\widehat \nabla V_n^{\theta_n}(x^0)$ and the Hessian estimate $\widehat{H_n}$ can be shown to be an $O(\delta_n^2)$ term away from the true gradient $\nabla V^\theta_n(x^0)$ and Hessian $\nabla^2  V^\theta_n(x^0)$, respectively (see Lemmas \ref{lemma:2spsa-bias}--\ref{lemma:2spsa-grad}).

%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
\algblock{PEvalPrimeDouble}{EndPEvalPrimeDouble}
\algnewcommand\algorithmicPEvalPrimeDouble{\textbf{\em CPT-value Estimation (Trajectory 3)}}
 \algnewcommand\algorithmicendPEvalPrimeDouble{}
\algrenewtext{PEvalPrimeDouble}[1]{\algorithmicPEvalPrimeDouble\ #1}
\algrenewtext{EndPEvalPrimeDouble}{\algorithmicendPEvalPrimeDouble}
\algtext*{EndPEvalPrimeDouble}

\algblock{PImpNewton}{EndPImpNewton}
\algnewcommand\algorithmicPImpNewton{\textbf{\em Newton step}}
 \algnewcommand\algorithmicendPImpNewton{}
\algrenewtext{PImpNewton}[1]{\algorithmicPImpNewton\ #1}
\algrenewtext{EndPImpNewton}{\algorithmicendPImpNewton}

\algtext*{EndPImpNewton}

%%%%%%%%%%%%%%%%%%%

\begin{algorithm}[t]
\begin{algorithmic}
\State {\bf Input:} initial parameter $\theta_0$, perturbation constants $\delta_n>0$, trajectory lengths $\{m_n\}$, step-sizes $\{\gamma_n, \xi_n\}$. 
\For{$n = 0,1,2,\ldots$}	
	\State Generate $\{\Delta_n^{i}, \widehat\Delta_n^{i}, i=1,\ldots,d\}$ using Rademacher distribution, independent of $\{\Delta_m, \widehat \Delta_m, m=0,1,\ldots,n-1\}$
	\PEval
	    \State Simulate $m_n$ samples  using parameter $(\theta_n+\delta_n (\Delta_n + \hat \Delta_n))$
	    \State Obtain CPT-value estimate $\widehat V_n^{(\theta_n+\delta_n (\Delta_n+\hat \Delta_n))}(x^0)$ using Algorithm \ref{alg:holder-est}
	    \EndPEval
	    \PEvalPrime
  	    \State Simulate $m_n$ samples using parameter $(\theta_n-\delta_n (\Delta_n + \hat \Delta_n))$
	    \State Obtain CPT-value estimate $\widehat V_n^{\theta_n-\delta_n (\Delta_n+\hat\Delta_n)}(x^0))$ Algorithm \ref{alg:holder-est}
	    \EndPEvalPrime
	    	    \PEvalPrimeDouble
  	    \State Simulate $m_n$ samples using parameter $\theta_n$
	    \State Obtain CPT-value estimate $\widehat V_n^{\theta_n}(x^0))$ using Algorithm \ref{alg:holder-est}
	    \EndPEvalPrimeDouble
	    \PImpNewton
		\State Gradient estimate $\widehat \nabla_{i} \C(X^\theta_n)\quad=\quad\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} - \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n}}{2\delta_n \Delta_n^{i}}$
        \State Hessian estimate $\widehat H_n\quad=\quad\dfrac{\overline \C_n^{\theta_n+\delta_n(\Delta_n+\widehat\Delta_n} + \overline \C_n^{\theta_n-\delta_n(\Delta_n+\widehat\Delta_n} - 2\widehat \nabla_{i} \C(X^\theta_n)}{\delta_n^2 \Delta_n^{i}\widehat\Delta_n^j}$

		\State Update the parameter and Hessian according to \eqref{eq:2spsa}--\eqref{eq:2spsa-H}
		\EndPImpNewton
\EndFor
\State {\bf Return} $\theta_n$
\end{algorithmic}
\caption{Structure of CPT-SPSA-N algorithm.}
\label{alg:structure-2}
\end{algorithm}

\subsection{Update rule}
We update the parameter incrementally using a Newton decrement as follows: For $i=1,\ldots,d$,
\begin{align}
\label{eq:2spsa}
% \theta_{n+1} =& \theta_{(1-\xi)\Theta}(\theta_n - \gamma_n \Upsilon(\overline H_n)^{-1} \widehat\nabla V^\theta_n(x^0)), \\
\theta^{i}_{n+1} =& \Gamma_{i}\left(\theta^{i}_n - \gamma_n \sum_{j=1}^{\L\M} M_n^{i,j} \widehat \nabla_{j} \C(X^\theta_n)\right), \\
\overline H_n = & (1-\xi_n) \overline H_{n-1} + \xi_n \widehat H_n,\label{eq:2spsa-H}
\end{align}
where $\xi_n$ is a step-size sequence that satisfies 
$\sum_{n} \xi_n = \infty, \sum_n \xi_n^2 < \infty$ and $\frac{\gamma_n}{\xi_n}\rightarrow 0$ as $n\rightarrow \infty$. These conditions on $\xi_n$ ensure that the updates to $\overline H_n$ proceed on a timescale that is faster than that of $\theta_n$ in \eqref{eq:2spsa} - see \cite[Chapter 6]{borkar2008stochastic}.
Further, $\Gamma$ is a projection operator as in CPT-SPSA-G and  $M_n = \Upsilon(\overline H_n)^{-1}$.
% ,  $\widehat\nabla V^\theta_n(x^0)$ is an estimate of the gradient of the CPT-value function and $\widehat H_n$ and $\overline H_n$ denote the Hessian estimate and its smooth counterpart, respectively. 
Notice that we invert $\overline H_n$ in each iteration, and to ensure that this inversion is feasible (so that the $\theta$-recursion descends), we project $\overline H_n$ onto the set of positive definite matrices using the operator $\Upsilon$. The operator has to be such that asymptotically $\Upsilon(\overline H_n)$ should be the same as $\overline H_n$ (since the latter would converge to the true Hessian), while ensuring inversion is feasible in the initial iterations.  The assumption below makes these requirements precise.\\[1ex]
\textbf{Assumption (A4).}  For any $\{A_n\}$ and $\{B_n\}$,
${\displaystyle \lim_{n\rightarrow \infty} \left\| A_n-B_n \right\|}= 0 \Rightarrow {\displaystyle \lim_{n\rightarrow \infty} \parallel \Upsilon(A_n)- \Upsilon(B_n) \parallel}= 0$. Further, for any $\{C_n\}$  with
${\displaystyle \sup_n \parallel C_n\parallel}<\infty$,
${\displaystyle \sup_n \left(\parallel \Upsilon(C_n)\parallel + \parallel \{\Upsilon(C_n)\}^{-1} \parallel\right) < \infty}$
as well.
\\[0.5ex]
%A simple way to define $\Upsilon(\overline H_n)$ is to first perform an eigen-decomposition of $\overline H_n$, followed by projecting all the eigen values onto the positive side (see \cite{gill1981practical} for a similar operator). 
A simple way to ensure the above is to have $\Upsilon(\overline H_n)$ as a diagonal matrix and then add a positive scalar $\delta_n$ to the diagonal elements so as to ensure invertibility  - see \cite{gill1981practical}, \cite{spall2000adaptive} for a similar operator.
%- this choice satisfies requirement (ii) in Theorem \ref{thm:2spsa} presented below.

%We next specify how the gradient $\widehat \nabla_i V^\theta_n(x^0)$ and Hessian $\widehat H_n$ estimates are obtained using SPSA.
The overall flow on CPT-SPSA-N is similar to Fig. \ref{fig:algorithm-flow}, except that three system trajectories with a different perturbation sequence are used. Algorithm \ref{alg:structure-2} presents the pseudocode.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Convergence result}
\begin{theorem}
\label{thm:2spsa}
Assume (A1)-(A4). 
Consider the ODE: 
$$
\dot\theta^{i}_t = \check\Gamma_{i}\left( - \Upsilon(\nabla^2 \C(X^{\theta_t}))^{-1} \nabla \C(X^{\theta^{i}_t}) \right), \text { for }i=1,\dots,d,$$
where 
$\bar\Gamma_{i}$ is as defined in Theorem \ref{thm:1spsa-conv}. Let $\K = \{\theta \in \Theta \mid
\nabla \C(X^{\theta^{i}})  \check\Gamma_{i}\left(-\Upsilon(\nabla^2 \C(X^{\theta}))^{-1} \nabla \C(X^{\theta^{i}})\right)
=0, \forall i=1,\ldots,d\}$. Then,
we have
$$\theta_n \rightarrow \K  \text{~~ a.s. as } n\rightarrow \infty.$$ 
\end{theorem}
\begin{proof}
 See Section \ref{appendix:2spsa}.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Gradient-free CPT-value optimization algorithm (GF-CPT)}
\label{sec:mras}
We perform a non-trivial adaptation of the algorithm from \cite{chang2013simulation} to our setting of optimizing CPT-value in MDPs.
We require that there exists a unique global optimum $\theta^*$ for the problem $\min_{\theta \in \Theta} \C(X^\theta).$

\subsection{Basic algorithm}
To illustrate the main idea in the algorithm, assume we know the form of $\C(X^\theta)$. Then, the idea is to generate a sequence of reference distributions $g_k(\theta)$ on the parameter space $\Theta$, such that it eventually concentrates on the global optimum $\theta^*$. One simple way, suggested in Chapter 4 of \cite{chang2013simulation} is
\begin{equation}
\label{eqn:naive}
g_{k}(\theta)=
\frac{\mathcal{H}(\C(X^\theta))g_{k-1}(\theta)}
{\int_{\theta}\mathcal{H}(\C(X^{\theta'}))g_{k-1}(\theta')\nu(d\theta')},
~~\forall\, \theta \in \theta,
\end{equation}
where $\nu$ is the Lebesgue/counting measure on $\theta$ and $\mathcal{H}$ is a strictly decreasing function. The above construction for $g_k$'s assigns more weight to policies having lower CPT-values and it is easy to show that $g_k$ converges to a point-mass concentrated at $\theta^*$.

Next, consider a setting where one can obtain the CPT-value $\C(X^\theta)$ (without any noise) for any policy $\theta$. In this case, we consider a family of parameterized distributions, say $\{f(\cdot,\eta),\,\eta\in \C \}$ and incrementally update the distribution parameter $\eta$ such that it minimizes the following KL divergence:
\begin{equation}\label{eqn:kl}
\mathcal{D}(g_k,f(\cdot,\eta)):=E_{g_k}\left[\ln \frac{g_{k}(\mathcal{R}(\theta))}{f(\mathcal{R}(\theta),\eta)}\right]=\int_{\theta} \ln \frac{g_{k}(\theta)}{f(\theta,\eta)}g_{k}(\theta)\nu(d\theta), \nonumber
\end{equation}
where $\mathcal{R}(\theta)$ is a random vector taking values in the policy space $\theta$. 
%Through \ e intuition for the above is that we project the reference distributions $g_k$ onto the family $\{f(\cdot,\eta),\,\eta\in \C \}$.
An algorithm to optimize CPT-value in this \textit{noise-less} setting would perform the following update for the parameter $\eta_n$:
\begin{equation}
\label{eqn:interior}
\eta_{n+1} \in \argmin_{\eta \in \C}
E_{\eta_n}\left[\frac{[\mathcal{H}(\C(X^{\mathcal{R}(\theta)}))]^{n}}
{f(\mathcal{R}(\theta),\eta_{n})}
\ln f(\mathcal{R}(\theta),\eta)\right],
\end{equation}
where $E_{\eta_n}[\C(X^{\mathcal{R}(\theta)})]=\int_{\theta} V^{\theta}(x^0)f(\theta,\eta_n)\nu(d\theta).$



%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
\algblock{Candidate}{EndCandidate}
\algnewcommand\algorithmicCandidate{\textbf{\em Candidate Policies}}
 \algnewcommand\algorithmicendCandidate{}
\algrenewtext{Candidate}[1]{\algorithmicCandidate\ #1}
\algrenewtext{EndCandidate}{\algorithmicendCandidate}
%%%%%%%%%%%%%%%%%%%
\algblock{Estimation}{EndEstimation}
\algnewcommand\algorithmicEstimation{\textbf{\em CPT-value Estimation}}
 \algnewcommand\algorithmicendEstimation{}
\algrenewtext{Estimation}[1]{\algorithmicEstimation\ #1}
\algrenewtext{EndEstimation}{\algorithmicendEstimation}
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\algblock{Elite}{EndElite}
\algnewcommand\algorithmicElite{\textbf{\em Elite Sampling}}
 \algnewcommand\algorithmicendElite{}
\algrenewtext{Elite}[1]{\algorithmicElite\ #1}
\algrenewtext{EndElite}{\algorithmicendElite}
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\algblock{Thresholding}{EndThresholding}
\algnewcommand\algorithmicThresholding{\textbf{\em Thresholding}}
 \algnewcommand\algorithmicendThresholding{}
\algrenewtext{Thresholding}[1]{\algorithmicThresholding\ #1}
\algrenewtext{EndThresholding}{\algorithmicendThresholding}
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\algblock{Update}{EndUpdate}
\algnewcommand\algorithmicUpdate{\textbf{\em Sampling Distribution Update}}
 \algnewcommand\algorithmicendUpdate{}
\algrenewtext{Update}[1]{\algorithmicUpdate\ #1}
\algrenewtext{EndUpdate}{\algorithmicendUpdate}
%%%%%%%%%%%%%%%%%%%
\algtext*{EndCandidate}
\algtext*{EndEstimation}
\algtext*{EndElite}
\algtext*{EndThresholding}
%%%%%%%%%%%%%%%%%%%

\begin{algorithm}
\begin{algorithmic}
\State {\bf Input:}  family of distributions $\{f(\cdot,\eta)\}$, initial parameter vector $\eta_0$ s.t. $f(\theta,\eta_0)>0 ~\forall\, \theta\in \theta$, trajectory lengths $\{m_n\}$, 
$\rho_0 \in (0,1]$, $N_0>1$,
$\varepsilon> 0$, $\alpha>1$, $\lambda \in(0,1)$,
strictly decreasing function
$\mathcal{H}\hspace*{-3pt}$.

\For{$n = 0,1,2,\ldots$}	
	\Candidate
	    \State 
	    Generate $N_n$ policies using the mixed distribution $\widetilde f(\cdot,\eta_n)= (1-\lambda)f(\cdot,\widetilde\eta_n)+\lambda f(\cdot,\eta_0)$. 
	    \State Denote these candidate policies by $\Lambda_n=\{\theta^1_n, \ldots, \theta^{N_n}\}$.
	\EndCandidate    
	\Estimation
	    \For{$i = 1,2,\ldots,N_n$}
	      \State Simulate $m_n$ samples using policy $\theta^i_n$
	      \State Obtain CPT-value estimate $\overline \C_n^{\theta^i_n}$ using Algorithm \ref{alg:holder-est}
	      \EndFor
	\EndEstimation
	%%%%%%%%%%%%%%%%%%%%%%%%%%55
	\Elite
	  \State Order the CPT-value estimates\footnotemark[1] $\{\overline \C_n^{\theta^{(1)}_n},\ldots,\overline \C_n^{\theta^{(N_n)}_n}\}$. 
	  \State Compute the $(1-\rho_n)$-quantile from the above samples as follows: 
	  \begin{align}
\widetilde \chi_{n}(\rho_n,N_n) = \overline \C_n^{\theta^{\lceil(1-\rho_k)N_k \rceil}_n}.\label{eq:quant}
\end{align}
	\EndElite
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\Thresholding
	\If {$n=0$ or $\widetilde\chi_{n}(\rho_n,N_n)\geq \bar\chi_{n-1}+\varepsilon$}
	    \State Set $\bar \chi_{k} = \widetilde \chi_{k}(\rho_n,N_n),~\rho_{k+1} = \rho_n,~N_{k+1} = N_{k}$ and \label{step:3a}
	    \State Set $\theta^*_{n} = \theta_{1-\rho_{n}}$, where $\theta_{1-\rho_{n}}$ is the policy that corresponds to the $(1-\rho_n)$-quantile in \eqref{eq:quant}.
	\Else
             \State find the largest $\bar \rho \in (0, \rho_n)$ such that $\widetilde\chi_{n}(\bar \rho,N_n)\geq \bar\chi_{n-1}+\varepsilon$;             
             \If {$\bar \rho$ exists} 
              \State Set $\bar \chi_{n} = \widetilde \chi_{n}(\bar \rho,N_n),~ \rho_{k+1}  = \bar \rho,~N_{n+1} = N_{n}$ and
              $\theta^*_{n} = \theta_{1- \bar \rho}$ \label{step:3b}
              \Else
	      \State Set $\bar \chi_{n}  = \widehat V_n^{\theta^*_{n-1}}(x^0)$,$\rho_{n+1} = \rho_n$,$N_{n+1} = \lceil\alpha N_{n}\rceil,$ and
          $\theta^*_{n} = \theta^*_{n-1}$.\label{step:3c}
	      \EndIf
         \EndIf
	\EndThresholding
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
	    \Update
		\State Parameter update\footnotemark[2]:  
		                         \begin{equation*} 
\eta_{n+1} \in \argmin_{\eta \in \C}\frac{1}{N_n}\sum_{i=1}^{N_n}\frac{[\mathcal{H}(\overline \C_n^{\theta^i_n})]^n}{\widetilde f(\theta,\eta_n)}
\widetilde I\big(\overline \C_n^{\theta^i_n},\bar \chi_{n}\big) \ln f(\theta,\eta).
                            \end{equation*}

		\EndUpdate
\EndFor
\State {\bf Return} $\theta_n$
\end{algorithmic}
\caption{Structure of  GF-CPT-MPS algorithm.}
\label{alg:mras}
\end{algorithm}

\footnotetext[1]{Here $\widehat V_n^{\theta^{(i)}_n}(x^0)$ denotes the $i$th order statistic.}
\footnotetext[2]{Here $\widetilde I(z,\chi):=\left\{\begin{array}{ll}
                                                          0 & ~\mbox{if $z\leq \chi-\varepsilon$,} \\
									    (z-\chi+\varepsilon)/ \varepsilon & ~\mbox{if $\chi-\varepsilon<z<\chi$,}\\
                                                          1 & ~\mbox{if $z\geq \chi$.}
                                                          \end{array} \right.$}
                    
Finally, we get to our setting where we only obtain a biased estimate of the CPT-value $\C(X^\theta)$ for any policy $\theta$. Recall that the bias is due to a finite sample run followed by the estimation scheme outlined in Algorithm \ref{alg:holder-est}. As in the case of SPSA-based algorithms, it is easy to see that the number of samples $m_n$ (in iteration $n$) should asymptotically increase to infinity. Assuming this setup, the gradient-free model-based policy search algorithm would involve the following steps (see Algorithm \ref{alg:mras} for the pseudocode):

\begin{description}
 \item[Step 1 (Candidate policies):] Generate $N_n$ policies $\{\theta^1_n, \ldots, \theta^{N_n}_n\}$ using the distribution $f(\cdot,\eta_n)$.

\item[Step 2 (CPT-value estimation):] Obtain $m_n$ samples for each of the parameters in $\theta^i_n, i=1,\ldots, N_n$ and return CPT-value estimates $\overline \C_n^{\theta^i_n}$.

\item[Step 3 (Parameter update):]
                         \begin{equation} \label{eqn:step4}
                           \eta_{n+1} \in \argmin_{\eta \in \C}\frac{1}{N_n}\sum_{i=1}^{N_n}\frac{[\mathcal{H}( \overline \C_n^{\theta^i_n})]^n}{ f(\theta_n^i,\eta_n)}\ln f(\theta_n^i,\eta).
                            \end{equation}

\end{description}

                    
A few remarks are in order.
\begin{remark}(\textbf{\textit{Choice of sampling distribution}})
A natural question is how to compute the KL-distance \eqref{eqn:kl} in order to update the policy. A related question is how to choose the family of distributions $f(\cdot,\theta)$, so that the update \eqref{eqn:interior} can be done efficiently. One choice is to employ the natural exponential family (NEF) since it ensures that the KL distance in \eqref{eqn:kl} can be computed analytically. %See Appendix \ref{appendix:mras} for details.
\end{remark}

\begin{remark}(\textbf{\textit{Elite sampling}})
In practice, it is efficient to use only an elite portion of the candidate policies that have been sampled in order to update the sampling distribution $f(\cdot,\eta)$. This can be achieved by using a quantile estimate of the CPT-value function corresponding to candidate policies that were estimated in a particular iteration. The intuition here is that using policies that have performed well guides the policy search procedure towards better regions more efficiently in comparison to an alternative that uses all the candidate policies for updating $\eta$.
\end{remark}

\subsection{Convergence result}
\begin{theorem}\label{thm:mras}
%Let $\varphi>0$ be a positive constant satisfying the condition that the set $\big\{\theta:\mathcal{H}(\C(D^\theta)\geq \frac{1}{\varphi} \big\}$ has a strictly positive Lebesgue/counting measure\index{Lebesgue measure}\index{counting measure}.
Assume (A1)-(A2). Suppose that multivariate normal densities are used for the sampling distribution, i.e., $\eta_n = (\mu_n, \Sigma_n)$, where $\mu_n$ and $\Sigma_n$ denote the mean and covariance of the normal densities.
Then, 
\begin{equation}\label{eqn:smain}
\lim_{n\rightarrow \infty}\mu_n=\theta^* \text{ and } \lim_{n\rightarrow \infty}\Sigma_n=0_{d\times d}~~a.s.
\end{equation}
\end{theorem}
\begin{proof}
 See Section \ref{appendix:mras}.
\end{proof}

